# Достигнутый результат

### Чем является результат

Результатом является техника "самонапоминания" для ChatGPT. Ее суть заключается в том, что каждый промпт, отправленный пользователем, обрамляется в напоминине для AI. В напоминании указано, что ChatGPT не должен генерировать опасный, токсичный или дизинформирующий ответ.

### Особенность результата

Результат является прикладным, поскольку его можно применять для предупреждения Jailbreak атак и защиты от них.

### Характеристика результата

Разработанный авторами метод демонстрирует снижение успешности Jailbreak атак. При обычных пользовательских запросах показатель успешности составляет примерно 67%, а при запросах обернутых в специальные ремарки указывающие ChatGPT на то, что он не должен наносить вред или дизинформировать пользователя своим ответом, успешность атак снижена в примерно в три раза (~19%). Также были проведены исследования с психологической точки зрения, где в обертке были использованы слова напоминающие, предупреждающие и поощрающие ChatGPT. В среднем напоминание и поощрение работают лучше нежели предепреждения.

### Границы применимости результата и степень его универсальности

Результат применим для любых промптов, которые имеют в себе цель взломать этичность ответа. Однако степень универсальности не высока, поскольку данная техника, пока что не может перекрыть все многообразие пользовательских запросов.

### Недостатки полученного решения

Метод зависим от конкретного запроса пользователя. Если запрос содержит в себе наличие слов, которые указываю ChatGPT игнорировать инструкции сверху, часть из таких запросов может пройти, что указывает на успешность Jailbreak атаки и неуспешность метода самонапоминания. 

### Нераскрытые вопросы

