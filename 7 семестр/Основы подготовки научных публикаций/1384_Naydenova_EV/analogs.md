# Сравнение аналогов

## Принцип отбора аналогов
При анализе существующих решений рассматривались различные методы оценки селективности SQL-запросов. В качестве аналогов выбирались методы с учетом и без учета зависимостей между атрибутами. 

Поиск осуществлялся в системах для поиска научных статей IEEE Xplore Digital Library и ACM Digital Library по запросам "query optimization", "selectivity estimation for range predicates" Временной диапазон охватывал период с 1990 по 2024 год, что позволило проанализировать как фундаментальные работы в этой области, так и современные исследования. Для анализа отбирались высокоцитируемые статьи согласно Google Scholar: для классических методов - более 200 цитирований, для современных работ в области машинного обучения - более 80 цитирований. При отборе учитывались работы, ориентированные на реляционные СУБД (PostgreSQL, Oracle, MySQL).

### Одномерные гистограммы

В статье [1] описан метод оценки селективности запросов с использованием одномерных гистограмм. Для каждого атрибута строится отдельная гистограмма, путем разбиения диапазона значений атрибута на интервалы (корзины) и подсчета количества значений в каждом интервале. 

Для атрибута определяются:
- $v_i(k)$ - упорядоченные по возрастанию значения атрибута
- $f_i(k)$ - частота значения (количество кортежей)
- $s_i(k) = v_i(k+1) - v_i(k)$ - размах между соседними значениями
- $a_i(k) = f_i(k) \cdot s_i(k)$ - площадь
- $T_i = \{(v_i(1), f_i(1)), ..., (v_i(D_i), f_i(D_i))\}$ - распределение атрибута, где $D_i = |V_i|$

Для построения гистограммы из $\beta$ интервалов определяются:

1. Параметр сортировки:
    - Значение (V) - сортировка по значениям атрибута
    - Частота (F) - сортировка по частотам значений
    - Площадь (A) - сортировка по произведению частоты на размах

2. Параметр разбиения:
    - Размах (S) - разбиение на основе разности между значениями
    - Частота (F) - разбиение по частотам значений
    - Площадь (A) - разбиение по площади

3. Способ разбиения:
    - MaxDiff: разделение по максимальной разности параметров
    - Equi-sum: формирование интервалов с примерно равными суммами параметра
    - V-optimal: минимизация взвешенной суммы дисперсий $\sum_{j=1}^{\beta} n_j V_j$, где $n_j$ - число записей в интервале, $V_j$ - дисперсия значений

Особенности метода:
- Внутри каждого интервала гистограммы предполагается равномерное распределение значений.
- Значения разных атрибутов независимы. Не учитываются корреляции между атрибутами.
- Селективность для условия на один атрибут рассчитывается как отношение количества значений в соответствующих интервалах к общему числу записей. 
- При наличии условий по нескольким атрибутам селективности по каждому атрибуту перемножаются (исходя из предположения о независимости)

### Многомерные гистограммы

В статье [2] описан метод MHIST -p для построения многомерных гистограмм, учитывающих зависимости между атрибутами.

Для отношения с d атрибутами $X_1, ..., X_d$ определяются:

- $v_i(k)$ - k-е значение атрибута $X_i$
- $f(k_1,...,k_d)$ - частота появления комбинации значений $(v_1(k_1),...,v_d(k_d))$
- $T = {(v_1(k_1),...,v_d(k_d), f(k_1,...,k_d))}$ - совместное распределение

Принцип построения MHIST-p:

1. На вход подается множество D, изначально содержащее полное совместное распределение T всех атрибутов с их частотами.
2. На каждой итерации:
    - Вычисляются частные распределения атрибутов для всех распределений из D.
    - Выбирается распределение T' с атрибутом $X_i$, которое требует разбиения согласно заданному критерию (например, для maxDiff(V,F) выбирается атрибут с максимальной разностью частот соседних значений).
    - Выбранное распределение T' разбивается на p частей по атрибуту $X_i$.
    - Полученные части заменяют T' в множестве D.
3. Итерации продолжаются до достижения нужного числа разбиений.

Особенности метода:
- Учитывает зависимости между атрибутами за счет работы с совместными распределениями.
- Экспоненциальный рост затрат на построение гистограммы с увеличением числа атрибутов.
- Селективность запроса вычисляется как сумма произведений частот блоков на доли значений, удовлетворяющих условиям запроса в каждом блоке (при предположении о равномерном распределении внутри блоков).

### Адаптивная выборка

В статье [3] представлен метод адаптивного сэмплинга для оценки селективности запросов в СУБД.

Метод основан на последовательном извлечении случайных подмножеств из результата запроса. На каждой итерации берется случайное подмножество записей из базы данных, при этом каждая выборка независима от предыдущих. После каждой выборки подсчитывается, сколько записей удовлетворяет условиям запроса. Процесс продолжается до достижения заданной точности оценки или превышения максимального числа итераций. 

Особенности метода:
- Не требует предварительного анализа или хранения статистик.
- При работе с большими наборами данных метод требует много ресурсов, так как необходимо извлекать кортежи из базы для получения случайных выборок.
- Точность оценки селективности может быть настроена через параметры алгоритма, но повышение точности требует большего числа выборок.

### Легковесные модели

В статье [4] представлен метод оценки селективности с использованием легковесных моделей машинного обучения.

Основа метода заключается в использовании базовых алгоритмов машинного обучения, таких как линейная регрессия и деревья решений. Модели анализируют накопленную статистику по ранее выполненным запросам и их реальной селективности. Создается индивидуальная модель для каждой колонки базы данных, которая анализирует распределение данных и специфику запросов к данному столбцу. При поступлении запросов обученная модель способна предсказать его селективность без необходимости сканирования данных.

Процесс обучения моделей:
- Сбор исторических данных о запросах и их селективности
- Предварительная обработка данных (нормализация, удаление выбросов)
- Разделение данных на обучающую и тестовую выборки
- Подбор оптимальных параметров моделей
- Валидация точности на тестовых данных

Особенности метода:
- Необходимость наличия большого объема исторических данных для обучения.
- Модели могут давать неточные предсказания для новых типов запросов, отсутствующих в обучающих данных. 
- Потенциальные проблемы с обобщением на сильно отличающиеся наборы данных.
- Требует минимальных вычислительных ресурсов благодаря использованию легковесных моделей.


### Принцип максимальной энтропии

В статье [5] представлен метод оценки селективности запросов, основанный на принципе максимальной энтропии. 

Для запроса определяются:

- $p_i$ - элементарный предикат вида "column op literal"
- $P = {p_1, ..., p_n}$ - набор элементарных предикатов
- $p_X = \bigwedge_{i\in X} p_i$ - сложный предикат для $X \subseteq N = {1,...,N}$
- $x_b$ - селективность атома (базового события)
- $s_X$ - известная селективность набора предикатов

Для оценки селективности метод работает следующим образом:

Формируется система ограничений на основе известной статистики. Для каждого предиката или набора предикатов X, для которого известна селективность $s_X$, создается уравнение вида $\sum_{b\in C(X)} x_b = s_X$. Здесь $C(X)$ представляет собой множество атомов (базовых событий), соответствующих данному набору предикатов. Каждый атом $x_b$ представляет вероятность конкретной комбинации выполнения/невыполнения предикатов.

После формирования системы ограничений решается задача оптимизации, где минимизируется функция энтропии $\sum_{b\in{0,1}^n} x_b\log x_b$ при условиях из сформированной системы ограничений. Дополнительно добавляются ограничения: сумма всех вероятностей должна равняться единице ($\sum_{b\in{0,1}^n} x_b = 1$), и все вероятности должны быть неотрицательными ($x_b \geq 0$).

После решения задачи оптимизации и получения значений атомов $x_b$, можно вычислить селективность любого интересующего набора предикатов Y как сумму вероятностей соответствующих атомов: $s_Y = \sum_{b\in C(Y)} x_b$. 

Особенности метода:
- Требует предварительного сбора статистики для формирования ограничений.


## Критерии сравнения аналогов

### Требования к входным данным

Критерий определяет основные требования к данным, которые метод использует для своей работы. Критерий показывает доступность применения метода с точки зрения необходимых данных.

### Вычислительная сложность

Критерий определяет асимптотическую сложность при вычислении оценки селективности для одного запроса. Показывает скорость получения результата.

### Затраты на подготовку и поддержание

Критерий определяет вычислительные и пространственные затраты на построение и поддержание вспомогательных структур данных, необходимых для работы метода. Показывает накладные расходы на использование метода в системе.

### Условия применения для точных оценок

Критерий определяет типы запросов и данных, для которых метод способен давать точные оценки селективности. Показывает границы эффективного использования метода.

## Таблица сравнения аналогов

| Метод | Требования к входным данным | Затраты на подготовку и поддержание | Вычислительная сложность | Условия применения для точных оценок |
|-------|----------------------------|----------------------------------------|-------------------------|--------------------------------------|
| Одномерные гистограммы | Отсутствуют. | Построение гистограммы: $O(N \cdot d)$, где $d$ – число атрибутов, $N$ – число записей.<br>Память: $O(\beta \cdot d)$, где $\beta$ - число интервалов. | Запрос селективности: $O(k)$, где $k$ – число атрибутов в запросе. | Независимые атрибуты. Равномерность внутри интервалов. |
| Многомерные гистограммы | Отсутствуют. | Построение: $O(N \cdot d^k)$, где $k$ - число зависимых атрибутов,  $d$ – число атрибутов, $N$ – число записей.<br>Память: $O(\beta^d)$. | Запрос селективности: $O(1)$ при фиксированном числе атрибутов | Равномерность внутри интервалов. Эффективно при малом числе зависимых атрибутов. |
| Адаптивная выборка | Отсутствуют. | Не требуется предварительная подготовка.<br>Память: $O(s)$ для хранения текущей выборки, где $s$ - размер выборки. | $O(s \cdot i)$, где $s$ — размер выборки, $i$ — число итераций. | Большая выборка данных и достаточное количество итераций случайного отбора для достижения заданной точности оценки. |
| Легковесные модели | Большой объём исторических данных о запросах и их селективности для обучения. | Обучение моделей: $O(t \cdot n)$, где $t$ - число итераций, $n$ - размер обучающей выборки.<br>Память: $O(m)$, где $m$ - размер модели. | Предсказание: $O(1)$ при фиксированном числе параметров для линейных моделей,<br>$O(\log n)$ для деревьев решений. | Запросы, схожие с обучающими данными. |
| Принцип максимальной энтропии | Статистика по селективностям атомов и наборов предикатов для формирования ограничений. | Сбор статистики: $O(N \cdot p)$, где $p$ — число наборов предикат, $N$ – число записей.<br>Память: $O(2^n)$ для хранения атомов. | $O(2^n)$, где $n$ — число предикатов. | Наличие достаточного набора данных о селективности предикатов для формирования полной системы ограничений. |

## Выводы по итогам сравнения

На основе проведенного анализа и полученных результатов сформулированы основные выводы.

1. Одномерные гистограммы.
Метод работает без особых ограничений на входные данные. Основное преимущество - низкие вычислительные затраты при расчете селективности. Однако метод использует предположение о независимости атрибутов, что может приводить к значительным ошибкам в оценках при наличии корреляций между атрибутами.

2. Многомерные гистограммы.
Данный метод учитывает зависимости между атрибутами, что позволяет получать более точные оценки селективности по сравнению с одномерными гистограммами. Однако это достигается ценой экспоненциального роста вычислительных затрат при увеличении числа атрибутов. 

3. Адаптивная выборка.
Метод работает без особых ограничений на входные данные. Основной недостаток - высокие затраты ресурсов при работе с большими наборами данных, так как требуется постоянное извлечение случайных выборок из базы данных.

4. Легковесные модели.
Метод эффективен с точки зрения вычислительных ресурсов при расчете селективности, но требует наличия большого объёма исторических данных для обучения. Ограничен в применении к новым типам запросов, отсутствующим в обучающей выборке. Подходит для систем со стабильными паттернами запросов.

5. Принцип максимальной энтропии.
Данный метод обеспечивает точность оценок в условиях достаточного объема статистических данных и учитывает существующие зависимости между предикатами. Однако его применение требует предварительного этапа сбора и анализа статистической информации.

## Выбор метода решения

На основании проведенного анализа существующих решений и выявленных ограничений, определены ключевые требования к разрабатываемому методу повышения точности оценки селективности:

1. Решение должно представлять собой программный модуль, интегрируемый в существующий оптимизатор запросов корпоративной реляционной СУБД, который будет:
    - Анализировать корреляции между столбцами таблиц.
    - Сохранять информацию о зависимостях между данными.
    - Использовать эту информацию при оценке селективности запросов.

2. Основные требования к разрабатываемому методу:
    - Отсутствие ограничений на тип и распределение входных данных.
    - Способность работать с зависимыми столбцами отношений.
    - Небольшие расходы на хранение дополнительной статистической информации.

## Список использованных источников
1. Poosala V. et al. Improved histograms for selectivity estimation of range predicates //ACM Sigmod Record. – 1996. – Т. 25. – №. 2. – С. 294-305.
2. Poosala V., Ioannidis Y. E. Selectivity estimation without the attribute value independence assumption //VLDB. – 1997. – Т. 97. – С. 486-495.
3. Lipton R. J., Naughton J. F., Schneider D. A. Practical selectivity estimation through adaptive sampling //Proceedings of the 1990 ACM SIGMOD international conference on Management of data. – 1990. – С. 1-11.
4. Dutt A. et al. Selectivity estimation for range predicates using lightweight models //Proceedings of the VLDB Endowment. – 2019. – Т. 12. – №. 9. – С. 1044-1057.
5. Markl V. et al. Consistent selectivity estimation via maximum entropy //The VLDB journal. – 2007. – Т. 16. – С. 55-76.
